### A. 结构化知识框架 (Module 10: Incremental Concept Learning)

**10.0 增量概念学习简介**

- **定位**: 课程中第二个关于“学习”的主要主题。
    
- **核心思想**: 从一系列**逐个**给出的、带标签（正例/反例）的示例中，**抽象**出概念的定义 。
    
- **与案例推理 (CBR) 的区别**:
    
    - **CBR**: 存储原始的、完整的案例以备将来**复用** 。
        
    - **增量概念学习**: 不存储原始案例，而是从案例中**抽象**出通用的概念定义或规则 。
        
- **学习特点**:
    
    - **增量式 (Incremental)**: 一次只处理一个示例 。
        
    - **监督式 (Supervised)**: 每个示例都被告知是正例还是反例 。
        
    - **顺序敏感 (Order-dependent)**: 示例的出现顺序会影响学习过程。
        
    - **小样本学习**: 通常从非常少的示例中学习，而不是数千或数百万个 。
        
    - **背景知识很重要**: 学习者已有的背景知识对如何进行泛化或特化起着关键作用 。
        

**10.1 增量概念学习的核心算法**

- **目标**: 维护一个当前的概念定义，使其能包含所有见过的正例，并排除所有见过的反例 。
    
- **基本流程**:
    
    - 1. 接收一个新示例及其标签（正/反）。
            
    - 2. **如果是正例**:
            
        
        - 检查当前定义是否**覆盖**该正例？
            
        - **是**: 什么都不做 。
            
        - **否**: **泛化 (Generalize)** 当前定义，使其能够覆盖这个新的正例 。
            
    - 3. **如果是反例**:
            
        
        - 检查当前定义是否**覆盖**该反例？
            
        - **否**: 什么都不做（定义已经能正确排除它）。
            
        - **是**: **特化 (Specialize)** 当前定义，使其能够排除这个反例 。
            

**10.2 学习过程中的基本操作与启发式方法**

- **初始步骤：变量化 (Variabilization)**
    
    - 当收到第一个（正）示例时，能做的唯一学习就是将示例中的具体实例（如“积木A”）替换为变量（如“一个积木”），形成初始的概念定义 。
        
- **泛化 (Generalization) 的启发式方法** (用于包含新的正例):
    
    - **丢弃链接 (Drop-Link)**: 如果新正例的结构比当前定义少了一个关系链接，则从定义中删除该链接 。
        
    - **扩大集合 (Enlarge-Set)**: 如果新正例中某个对象的类型不同，则将该类型加入到定义中对应位置的可选类型集合里（如从`brick`变为`brick or wedge`）。
        
    - **爬升知识树 (Climb-Tree)**: 如果背景知识表明多个可选类型（如`brick`, `wedge`）都属于同一个上层概念（如`block`），则用该上层概念替换它们，实现更高层次的泛化 。
        
    - **闭合区间 (Close-Interval)**: 对于连续值属性（如尺寸），扩大其允许值的范围以包含新正例 。
        
- **特化 (Specialization) 的启发式方法** (用于排除新的反例):
    
    - **要求链接 (Require-Link)**: 如果反例中缺少了某个关系链接，则在定义中将该链接标记为“必须存在” 。
        
    - **禁止链接 (Forbid-Link)**: 如果反例中多了一个不该有的关系（如两个积木“接触”），则在定义中明确禁止该关系的存在 。
        

**10.3 认知连接 (The Cognitive Connection)**

- **与人类学习的相似性**:
    
    - 人类在日常生活中通常也是
        
        **增量式**学习，一次接触一个新事物，而不是一次性接收大量数据 。
        
    - 增量概念学习模型比许多需要海量数据进行统计分析的机器学习模型更接近人类的学习方式 。
        

---

### B. 文本思维导图 (Module 10)

- **Module 10: Incremental Concept Learning**
    
    - **核心定义**
        
        - _是什么_: 从逐个给出的、带标签的示例中**抽象**出概念的过程 。
            
        - _与CBR的区别_: CBR是**复用**案例，ICL是**抽象**概念 。
            
        - _特点_: 增量式、监督式、小样本、依赖背景知识。
            
    - **核心算法流程**
        
        - _目标_: 维持一个能正确分类所有已知示例的概念定义。
            
        - **遇到新正例**:
            
            - _已被覆盖?_ -> 不变。
                
            - _未被覆盖?_ -> **泛化 (Generalize)** 定义以包含它 。
                
        - **遇到新反例**:
            
            - _已被排除?_ -> 不变。
                
            - _意外覆盖?_ -> **特化 (Specialize)** 定义以排除它 。
                
    - **具体学习操作 (Heuristics)**
        
        - _第一步_: **变量化 (Variabilization)** - 将实例常量变为变量 。
            
        - _泛化操作 (Generalization)_:
            
            - **Drop-Link**: 删除多余的关系约束。
                
            - **Enlarge-Set**: 扩大离散值的可选范围（`brick` -> `brick or wedge`）。
                
            - **Climb-Tree**: 利用背景知识，用上层概念替换下层概念集合 (`brick or wedge` -> `block`) 。
                
        - _特化操作 (Specialization)_:
            
            - **Require-Link**: 将某个关系标记为“必须存在”。
                
            - **Forbid-Link**: 明确禁止某个关系的存在（如`not-touches`）。
                
    - **认知连接**
        
        - _与人类学习方式相似_: 人类也是一次学习一个例子，逐步形成概念 。